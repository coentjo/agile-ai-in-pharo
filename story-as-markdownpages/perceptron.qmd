---
title: "Understanding the Perceptron"
---

## The Biological Inspiration: From Brain Neurons to Artificial Intelligence

The Perceptron represents one of the most fundamental concepts in artificial intelligence, drawing its inspiration directly from the human brain's neural structure. This groundbreaking idea was first introduced in 1943 by Warren S. McCulloch and Walter Pitts in their seminal paper 'A Logical Calculus of the Ideas Immanent in Nervous Activity', where they proposed a mathematical model of biological neurons.

![A typical biological neuron structure](attach/TypicalNeuron.png)

## From Biology to Machine: Implementing a Perceptron

A Perceptron's architecture elegantly mirrors its biological counterpart through three key components: `inputs`, `weights`, and a `bias`. Each input connection has an associated weight that determines its relative importance, while the bias helps adjust the Perceptron's overall sensitivity to activation.

![Perceptron's architectural diagram](attach/Perceptron01.png)

Let's explore a practical example with three inputs. We'll call our input values `x1`, `x2`, and `x3`, with their corresponding weights `w1`, `w2`, and `w3`. The Perceptron processes these inputs in two steps:

1. First, it calculates a `weighted sum` and adds the bias:
   `z := w1*x1 + w2*x2 + w3*x3 + bias`

2. Then, it applies an **activation function** to produce the final output:
   - Output is 1 if z > 0
   - Output is 0 if z â‰¤ 0

Here's how we can implement this in code:

```pharo
| x1 x2 x3 w1 w2 w3 bias |
"Define our input values"
x1 := 0.35 .
x2 := 1.2 .
x3 := 0.54 .
"Set the weights and bias"
w1 := 0.234 .
w2 := 0.32 .
w3 := 0.58 .
bias := 5 .
"Calculate the weighted sum with bias"
z := (w1 * x1) + (w2 * x2) + (w3 * x3) + bias.
```

The activation function then determines the final output:

```pharo
z > 0 
    ifTrue: [1]
    ifFalse: [0]
```

## A More Flexible Implementation

Let's examine a more versatile implementation that can handle any number of inputs:

```pharo
| inputs_x weights_w bias |
inputs_x :=  #(0.35  1.2  0.54).
weights_w := #(0.234 0.32 0.58).
bias := 5.
z := (inputs_x 
    with: weights_w 
    collect: [ :x :w | x * w ]) 
        sum 
            + bias
```

This implementation is more flexible because it can process any number of inputs, as long as there's a matching weight for each input value. Try experimenting with different input values to see how the Perceptron's output changes!

