---
title: "Introduction to Neural Networks"
---

## Beyond Single Perceptrons: Building Neural Networks

Having seen the limitations of single Perceptrons, we now venture into the fascinating world of neural networks. These powerful structures combine multiple Perceptrons in layers to solve complex problems that single Perceptrons cannot handle.

![Basic neural network architecture](attach/2021-AI-General.041.png)

## Understanding Network Architecture

A typical neural network consists of three main components:

1. **Input Layer**: Receives the raw data
2. **Hidden Layer(s)**: Processes the information through multiple Perceptrons
3. **Output Layer**: Produces the final result

### Key Components

Each connection in the network has:
- A weight that determines its strength
- A direction of information flow (forward only)
- An associated neuron that processes the incoming signals

## How Information Flows

The network processes information in these steps:

1. Input values are presented to the input layer
2. Each neuron in subsequent layers:
   - Receives weighted inputs from the previous layer
   - Applies its activation function
   - Passes the result to the next layer
3. The output layer produces the final result

## Creating a Simple Network

Here's how to create a basic neural network:

```pharo
network := NeuralNetwork new
    inputSize: 2;
    addHiddenLayer: 3;
    outputSize: 1;
    initialize.
```

This creates a network with:
- 2 input neurons
- 3 neurons in one hidden layer
- 1 output neuron

## Training the Network

Unlike single Perceptrons, neural networks use more sophisticated training algorithms:

```pharo
"Training data for XOR problem"
trainingData := #(
    ((0 0) 0)
    ((0 1) 1)
    ((1 0) 1)
    ((1 1) 0)
).

"Train the network"
1000 timesRepeat: [
    trainingData do: [:example |
        inputs := example first.
        desiredOutput := example second.
        network trainOn: inputs expecting: desiredOutput
    ]
].
```

## Advantages of Neural Networks

1. Can solve non-linearly separable problems
2. Handle complex pattern recognition
3. Learn hierarchical features automatically
4. Scale well to large problems

In the next sections, we'll explore practical applications and see how to train networks on real-world data.