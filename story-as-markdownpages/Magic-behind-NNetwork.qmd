---
title: "The Mathematics Behind Neural Networks"
---

## Understanding the Magic

While neural networks might seem magical, they're built on solid mathematical foundations. Let's demystify how they actually work under the hood.

## The Building Blocks

### 1. Neurons and Weights

Each neuron performs two key operations:
1. Weighted sum of inputs: $z = \sum_{i=1}^n w_i x_i + b$
2. Activation function: $a = f(z)$

Where:
- $w_i$ are the weights
- $x_i$ are the inputs
- $b$ is the bias
- $f$ is the activation function

### 2. Activation Functions

Common activation functions include:

1. Sigmoid: $f(x) = \frac{1}{1 + e^{-x}}$
   - Outputs between 0 and 1
   - Useful for probability predictions

2. ReLU (Rectified Linear Unit): $f(x) = \max(0, x)$
   - Simple and efficient
   - Helps prevent vanishing gradients

3. Tanh: $f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
   - Outputs between -1 and 1
   - Often better than sigmoid for hidden layers

## The Learning Process

### 1. Forward Propagation

Information flows through the network:
```pharo
"Example of forward propagation"
layer1Activation := (weights1 dot: inputs) + bias1.
layer1Output := activationFunction value: layer1Activation.
```

### 2. Loss Calculation

Measure the network's error:
$E = \frac{1}{2} \sum (target - output)^2$

### 3. Backpropagation

Update weights to minimize error:
$\Delta w = -\eta \frac{\partial E}{\partial w}$

Where $\eta$ is the learning rate.

## Gradient Descent Visualization

The network learns by descending the error surface:
1. Calculate error gradient
2. Take small steps in the opposite direction
3. Repeat until reaching a minimum

## Practical Implementation

In Pharo, we can implement these concepts:

```pharo
NeuralNetwork >> updateWeights: inputs error: error
    "Update weights using gradient descent"
    learningRate := 0.1.
    delta := error * self derivativeActivation: self lastOutput.
    weights := weights + (learningRate * (inputs * delta))
```

## Key Insights

1. Neural networks learn through iterative optimization
2. The choice of activation function matters
3. Learning rate affects training stability
4. Gradient descent finds local minima

## Beyond the Basics

Advanced concepts build on these foundations:
- Momentum for faster convergence
- Regularization to prevent overfitting
- Batch normalization for stability
- Advanced optimizers like Adam

Understanding these mathematical principles helps us:
1. Debug network issues
2. Choose appropriate architectures
3. Optimize performance
4. Innovate new solutions


