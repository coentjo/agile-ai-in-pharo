---
title: "Practical Applications of the Perceptron"
---

## Building Logic Gates with Perceptrons

Let's look at an example of how Perceptrons can be used? 

### Creating an AND Gate

You may know the concept of an AND gate: given two inputs (both can be `0` or `1`) the AND gate will output a `1` if both inputs are `1`, and `0` in all other cases. 

Consider a Perceptron with the following configuration:
- Weights: `w1 = 1`, `w2 = 1` 
- Bias: `-1.5`

Here's the truth table for an AND gate:

| Input 1 | Input 2 | Output |
|---------|---------|---------|
| 0       | 0       | 0       |
| 0       | 1       | 0       |
| 1       | 0       | 0       |
| 1       | 1       | 1       |


One example: when inputs are `1` and `1` the weighted sum is ($1 * 1 + 1 * 1$), adding the bias gives: `0.5`, which is greater than `0`, so the activation function will give `1`. 

## Beyond AND Gates

By changing the bias to `-0.5` this Perceptron turns into an OR gate (which returns `1` if at least one of the inputs is `1`)

Changing the values can give you a NOR gate and a NOT gate, which would be nice to figure out yourself (or use your prefered search engine). 

## Network

By combining several Perceptrons (sending the output of one to the input of another) you can probably imagine that it is possible to create Networks of Perceptrons. By changing the values of weights and biases of the connected Perceptrons it is possible to build complex electronic circuits.


So far, we've only looked at binary circuits where inputs and outputs are restricted to 0 and 1. However, when we generalize this concept to allow larger positive values, negative values, floating-point numbers, and different activation functions, the Perceptron becomes an incredibly versatile tool. This generalization opens up possibilities for pattern recognition, classification tasks, regression problems, and complex decision-making systems. This is where the true power of neural networks begins to emerge, as they can learn to handle continuous data and make sophisticated decisions based on multiple inputs.

In relatively simple cases it can be used as sort of a decision machine. More complex applications of this technology can help recognizing objects in the real world.

Up until now we didn't look at how a perceptron can learn and become smarter. That will be subject of next chapter chapters. The concept of a Perceptron was generalized to what we now call an (artificial) Neuron.

When combining Artificial Perceptrons/Neurons to Networks they are  referred to as
`Multi Layered Perceptron` (MLP) or `(Artificial) Neural Network` (ANN). 


## Reference

- [wikipedia: perceptron](https://en.wikipedia.org/wiki/Perceptron)

![The Mark I Perceptron machine, the first implementation of the perceptron algorithm (source: wikipedia)](Mark_I_perceptron.jpeg)


